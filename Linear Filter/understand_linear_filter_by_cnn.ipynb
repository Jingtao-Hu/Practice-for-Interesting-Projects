{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quansun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to transform color images into grayscale\n",
    "def make_grayscale(img):\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return gray_img\n",
    "\n",
    "# define a function to sobel filter images via x axis\n",
    "# you can change the filter\n",
    "def filter_sobelx(img):\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_32F,1,0,ksize=3)\n",
    "#   sobely = cv2.Sobel(img,cv2.CV_32F,0,1,ksize=3)\n",
    "    return sobelx\n",
    "\n",
    "# define a function to transform pixel values into [0,1]\n",
    "def normalizeImage(img):\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "# define a function to perform MinMaxScaler\n",
    "def MinMaxScaler(img):\n",
    "    img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to the training images\n",
    "data_path = 'data'\n",
    "\n",
    "folderpaths = [os.path.join(data_path,path) for path in os.listdir(data_path) if os.path.isdir(os.path.join(data_path,path))]\n",
    "imagepaths = []\n",
    "\n",
    "for folderpath in folderpaths:\n",
    "    temp = [os.path.join(folderpath,filename) for filename in os.listdir(folderpath) if filename.endswith('.jpg')]\n",
    "    imagepaths += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process training data\n",
    "images = []\n",
    "grayimages = []\n",
    "filteredimages = []\n",
    "\n",
    "np.random.shuffle(imagepaths)\n",
    "for imagepath in imagepaths:\n",
    "    img = cv2.imread(imagepath).astype(np.float32)\n",
    "    img = normalizeImage(img)\n",
    "    gray_img = make_grayscale(img)\n",
    "    filtered_img = filter_sobelx(gray_img)\n",
    "    images.append(img)\n",
    "    grayimages.append(gray_img)\n",
    "    filteredimages.append(filtered_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images).astype('float32')\n",
    "grayimages = np.array(grayimages).astype('float32')\n",
    "filteredimages = np.array(filteredimages).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of images: (2688, 256, 256, 3)\n",
      "The shape of grayimages: (2688, 256, 256)\n",
      "The shape of filteredimages: (2688, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of images:', images.shape)\n",
    "print('The shape of grayimages:', grayimages.shape)\n",
    "print('The shape of filteredimages:', filteredimages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need change the shape of grayimages and filterediamges\n",
    "grayimages = grayimages.reshape(-1,256,256,1)\n",
    "filteredimages = filteredimages.reshape(-1,256,256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin = np.ones(shape=(256,10,3))\n",
    "combined_image = np.hstack((img,margin,np.dstack((gray_img,)*3),margin,np.dstack((normalizeImage(filtered_img),)*3)))\n",
    "\n",
    "cv2.imwrite('sobelx.png',(255*combined_image).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 1)       10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1,(3,3),padding='same',input_shape=(256,256,1)))\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-2,decay=1e-6,momentum=0.9,nesterov=True),loss='mean_squared_error',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0540 - acc: 0.0489 - val_loss: 0.0273 - val_acc: 0.0501\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 8s 4ms/step - loss: 0.0253 - acc: 0.0475 - val_loss: 0.0240 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0242 - acc: 0.0474 - val_loss: 0.0237 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0240 - acc: 0.0474 - val_loss: 0.0236 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0239 - acc: 0.0474 - val_loss: 0.0235 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0238 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0238 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 5ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0498\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n",
      "Train on 2150 samples, validate on 538 samples\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.0474 - val_loss: 0.0234 - val_acc: 0.0499\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss = []\n",
    "val_loss = []\n",
    "weights = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    temp = model.fit(grayimages,filteredimages,\n",
    "                    batch_size=4,epochs=1,validation_split=0.2)\n",
    "    loss.append(temp.history['loss'][0])\n",
    "    val_loss.append(temp.history['val_loss'][0])\n",
    "    weights.append(model.layers[0].get_weights()[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('cnn_model_sobelx.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYVOWZ9/FvLQ0doGkBFURxFKI36BUQQaKjqBCMiIk7ToxLXFAZx/iO+EZBZTQJxgXEBYMGHAwokWgivqLGJe6AhEiiiMFbGzM6gCAoq6SbXur945xqTnV3Nd1QBaHr97mulq6zPqe6rF895z7nqVgqlUJERCQtvrsbICIi/1wUDCIikkHBICIiGRQMIiKSQcEgIiIZFAwiIpJBwSAtnpkdZGYpM3ujgXm/Duft3cxtPmtmF29nmRPNbEmW9mxuzv5EdiUFgxSKcsDM7F/SE8ysLXDs7muSyD+n5O5ugMguUg38Fjgf+EU47Szg/wHXpRcysyuAa8LlVwNXu/tHZtYVmA50BT4F9o2s0wu4D+gEJID73X3ajjTSzEqBXwJHACngD8CN7l5lZj8FzgS2Al8CF7v759mm78j+RUA9BiksM4ALI49/BPw6/cDMBgPXA4PcvQ/wG+BpM4sRvFkvcPfDCYKjZ7hOEvgdMNrd+wEnAP/XzI7ewTbeT/Dm/i2gP9An3F434D+Bo9y9P/AS8O1s03dw3yKAgkEKiLsvAqrNrF/4hlri7tEawFDgt+6+Jlz+18D+wEHAEMIQcfcy4NVwnUOBHsA0M3sXeAP4BtB3B5t5CvCAu6fcvQJ4KJy2AngP+IuZTQDedfenG5kussMUDFJoHgUuIOg5PFpnXoLg9E1UDCgKp8ci06si62xw9yPSP8DRwCM72L54nTbEgSJ3ryHojVxM0KO4x8zuyjZ9B/ctAigYpPA8BgwH/o3gVFHUC8APzGwfADO7hODNtiycd0U4/UBgULiOA/8wswvCed2AJUC/HWzfi8DVZhYzs9bhPl82sz7hdpe6++3APcBR2abv4L5FAAWDFBh3XwEsBT5296/qzHuZ4I31VTP7gKAG8b3wU/l/AIeZ2VLgv4F3w3W2AqcDI8xsMcE5/rHuPm87TWlrZpvr/HyLoH6xL/B++OPAbe7+HvAE8I6ZvQNcCozKNn2nniQpeDENuy0iIlHqMYiISAYFg4iIZFAwiIhIBgWDiIhk2OOHxAgv6TsK+JxgGAMREWlcAtgP+HN4I2WGvASDmcWByQS381cAI8K7RdPzLweuJLhJaJy7P2tmHYGPCK7JBpjt7veZ2f0EA51tCqef7u4bIrs7CngrH8chItLCDQTm1p2Yrx7DGUCxux8TjhlzN8G13phZF4JrtfsDxcBcM3sZOBJ43N1/XGdbRwInu/vaLPv6HGDmzJl06dIl90ciItLCrFq1ivPPPx/C98+68hUMxxHcKYq7LzCz/pF5A4B5YfelwszKgN4Ed4oeGY6Z/wVBeKwGDgGmmFln4L8bGLWyGqBLly4ccMABeTocEZEWqcHT7/kqPrcHoqd7qsNRKBuatwkoBT4EbnH3E4CngUlA2/DfCwgGOLvKzHrnqc0iIkL+gmEjUBLdj7tXZZlXAqwnGK3ytXDabILRKbcA97n7FnffFC7TJ09tFhER8hcM84BhAGGN4f3IvIXAQDMrDr+UpBdBwflh4Oxwme8AiwiGNJ5rZgkzKyI4RfWXPLVZRETIX41hNnCSmc0nGKr4EjMbBZS5+zPhlUZvEQTTTe5ebmajCca0vwr4muBKps/NbCawAKgEZrj7B3lqs4iI0AIG0TOzg4C/v/LKKyo+i4g0wfLly/nOd74DcLC7/0/d+brzWUREMhR0MPxgytv8btHy3d0MEcmDiooKnnzyySYv/9RTT/HKK69knT9lyhQWL168w+156qmnmDBhwg6vvyvt8UNi7IwlKzZyeNeNu7sZIpIHa9as4cknn2T48OFNWv6ss85qdP4VV1yRi2btEQo6GBLxGNU1e3aNRWRP8PtFy3ninf/N6TbP7d+Ns/tlrys+9NBDlJWV8cADD5BKpfjrX//Kli1buO2223j66adZsmQJX3/9NT169OD2229n0qRJ7L333nTv3p2pU6dSVFTE8uXLGTZsGP/+7//O6NGjGTZsGGvXruWNN96gvLyczz77jMsvv5yzzjqLxYsX89Of/pS2bdvSqVMnWrduzR133NFg26ZNm8Zzzz1HMpmkf//+/OQnP2HRokXceeedJJNJ2rdvz4QJE1izZg1jxowhmUySSCS466676Ny5c06fx4YU9KmkZDxGVU3N7m6GiOTByJEj+eY3v8nVV18NQPfu3Zk1axadO3emffv2PPLII8yaNYt3332X1atXZ6y7cuVKJk2axG9/+1sefvjhetvevHkzv/rVr3jwwQeZMmUKALfccgt33HEHM2bM4MADD8zaLnfnD3/4A7NmzWLWrFl8+umnvPbaa/zxj3/kpJNO4rHHHuOcc85h48aNzJ8/n8MPP5xHHnmEkSNHsmHDhqzbzaWC7zFUVavHIJJvZ/c7oNFP97vCwQcfDEDr1q356quvGDVqFG3atGHLli1UVlZmLHvooYeSTCZJJpMUFxfX21bPnj0B2G+//di6dSsAX3zxBYcccggA/fr14/nnn2+wHZ988gl9+vShqKgIgP79+/Pxxx8zcuRIHnroIX70ox/RuXNnevfuzTnnnMPUqVMZMWIEJSUlXHvttbl5MrajoHsMRYk4VTqVJNIixeNxaiJnBOLx4O3uzTff5PPPP2fixImMGjWK8vJy6l62H4vFGt12Q/O7dOlCWVkwiPR7772Xdd3u3buzePFiqqqqSKVS/PnPf+bggw9mzpw5nHnmmTz66KMccsghPPHEE7zyyiv069eP6dOnM3To0AZ7L/lQ8D0G1RhEWqZOnTpRWVnJ+PHjMz719+7dm8mTJ3PuuefSqlUrunXrxhdffLHT+7vlllu48cYbadOmDUVFRVlrAWbGKaecwnnnnUdNTQ39+vVjyJAhLF68mNGjR9eu/7Of/YxUKsVPfvITJk2aRDweZ8yYMTvdzqYo6BvcBk94ncP3L2XSeX3z0jYRKRwzZ87klFNOoWPHjtxzzz0UFRXV1jf+2WzvBreC7zFUVav4LCI7r1OnTlx66aW0adOGkpKSrFck7QkKOhiSqjGISI4MHTqUoUOH7u5m5ERBF5+TqjGIiNRT0MGQiMfUYxARqaOggyGpGoOISD2FHQwJ9RhEROoq7GCIx1VjEBEuvPBCli1blnWE1WOPPbbR9V9++WVWr17NmjVruPXWW3eqLYMHD6aiomKntrGzCjoYVGMQkaizzjorfX1/s8yYMYPNmzezzz777HQw/DMo7MtVVWMQ2TXefRz++lhut9n3AjjivKyzr776ai666CIGDBjA4sWLefDBBxk/fjw33XQTmzZtYt26dQwfPpwf/vCHteukR1g999xzGTt2LGVlZXTr1q12PKSPPvqIO+64g5qaGjZu3MjNN9/Mxo0bWbp0KTfccAPjx4/nhhtu4IknnmDevHnce++9tG7dmr322otf/OIXLF26tMGRWxuyfPlybrrpJqqqqojFYtx888307NmT0aNH89lnn1FRUcFll13GsGHDuOeee1iwYAE1NTWceuqpXHzxxTv11BZ2MCR0uapISzV8+HBmz57NgAEDmD17Nueeey6ffvopp556Kt/97ndZvXo1F154YUYwpL355ptUVFTwxBNPsHLlSl588UUAysrKuOGGGzAz5syZw1NPPcW4cePo1asXt956a+3AeKlUirFjx/L444/TuXNnpk+fzoMPPsiJJ57IypUreeaZZ9i6dSsDBw7MGgx33XUXF154IUOGDGHp0qXceOONzJgxgz/96U/8/ve/B2DevHkAPP300zz22GN07tyZp556aqefu8IOhrhucBPZJY44r9FP9/kwcOBAxo8fz/r163nnnXe4+eabWbt2LdOnT+ell16iXbt2VFVVNbjuxx9/TO/evQHo2rUr++23HwD77rsvkydPpri4mK+//pp27do1uP66deto165d7XhJRx11FBMnTuTEE0/c7sitacuWLeOoo44CoFevXqxatYp27doxduxYxo4dy+bNmznttNMAmDhxIhMnTmTt2rUMHDhwx56wiIKvMajHINIyxeNxhg4dyq233sqQIUNIJBJMmzaNI444ggkTJjB06NB6o6qmde/enXfffReA1atX135fw2233cY111zDnXfeyaGHHlq7fiwWy9hWhw4d2Lx5c+3gfAsXLuSggw6qXbYpevTowTvvvAPA0qVL2Xvvvfniiy/44IMP+OUvf8mUKVMYP348W7du5YUXXmDixIlMnz6d2bNns2LFiuY/YREF3mOIUakag0iLdfbZZzNkyJDaU0GDBg3i1ltvZc6cOey1114kEona+kHUkCFDWLRoEcOHD6dr16506NABgNNOO42rrrqKTp060aVLF9atWwdA3759uf766/n5z38OBG/+48aN48c//jGxWIzS0lJuv/12Pv744ya3/frrr2fs2LFMmzaNqqoqbrvtNvbZZx/WrFnDGWecQZs2bbj00ktp1aoVpaWlnH766ZSWlnLsscfStWvXnXreCnp01et/9x5vfbyWt8c0/yoEEZE91fZGVy3wU0mqMYiI1JWXU0lmFgcmA32ACmCEu5dF5l8OXAlUAePc/Vkz6wh8BCwJF5vt7vc1tGyu2qlB9ERE6stXjeEMoNjdjzGzo4G7gdMBzKwLcA3QHygG5prZy8CRwOPu/uP0RrIt6+45uS0woRqDiEg9+QqG44AXANx9gZn1j8wbAMwL39wrzKwM6A30A440szeALwgC4agsy/45F40s0n0MIiL15KvG0B7YEHlcbWbJLPM2AaXAh8At7n4C8DQwqZFlc0I1BhGR+vIVDBuBkuh+3L0qy7wSYD3wKvBaOG020LeRZXNCNQYRkfryFQzzgGEAYY3h/ci8hcBAMys2s1KgF0HB+WHg7HCZ7wCLGlk2J9I3uO3pl+yKiORSvmoMs4GTzGw+EAMuMbNRQJm7P2Nm9wNvEQTTTe5ebmajgWlmdhXwNcGVTKsaWjZXjSxKBHcgVtWkan8XESl0eQkGd68BRtaZ/GFk/lRgap11/g4MamBb9ZbNlUQ86DBV16QoSuRjDyIie56CvsEtGd/WYxARkUBBB0MiHQy6l0FEpFZBB0O0xiAiIoGCDoZojUFERAIFHQyqMYiI1FfQwaAag4hIfQUdDEnVGERE6insYFCNQUSknoIOhm2nkhQMIiJpBR0M24rPqjGIiKQVdjCoxiAiUk9hB4NqDCIi9RR0MKjGICJSX0EHw7ZTSaoxiIikFXYw6M5nEZF6CjwYwhqDTiWJiNQq6GBIqMcgIlJPQQeDagwiIvUVdjCEPQZdrioisk2BB0Nw+LpcVURkm4IOhkRCPQYRkboKOhjSp5IqVWMQEamlYEA9BhGRqAIPBtUYRETqKuhgUI1BRKS+ZD42amZxYDLQB6gARrh7WWT+5cCVQBUwzt2fjcw7Hpjp7t3Cx6OAy4A14SJXurvnop2qMYiI1JeXYADOAIrd/RgzOxq4GzgdwMy6ANcA/YFiYK6ZvezuFWbWDbgOKIps60jgIndflOtG1tYYdCpJRKRWvk4lHQe8AODuCwhCIG0AMM/dK9x9A1AG9DazYuAh4Ko62+oHjDGzuWY2JpeN1JAYIiL15SsY2gMbIo+rzSyZZd4moBR4AJjg7ivqbGsWMBIYDBxnZt/LVSNjsRiJeEw1BhGRiHwFw0agJLofd6/KMq8E2AoMBG4xs9eBjmY2y8xiwL3uvtbdtwLPAX1z2dBEPKYag4hIRL5qDPOA7wNPhDWG9yPzFgK3haeOWgO9gIXubukFzGyVu//AzEqBJWbWC/iaoNcwLZcNLYrHVGMQEYnIVzDMBk4ys/lADLgkvLqozN2fMbP7gbcIeiw3uXt5Qxtx9w1mdiPwGsHVTa+4+/O5bGgiHlONQUQkIi/B4O41BHWBqA8j86cCUxtZv0vk90eBR3PdxrRkIq4ag4hIREHf4AbpHoNqDCIiaQUfDEXxmIbEEBGJKPhgSCR0uaqISFTBB0MyHlfxWUQkouCDQTUGEZFMBR8MSdUYREQyKBhUYxARyVDwwZBQjUFEJEPBB0NSNQYRkQwKBtUYREQyKBhUYxARyVDwwaAag4hIpoIPhiLVGEREMhR8MCRUYxARyVDwwaAag4hIpoIPhkRc38cgIhJV8MFQpO98FhHJUPDBkNB3PouIZCj4YEgm9J3PIiJRBR8MibiKzyIiUQUfDMl4nMpq1RhERNIUDOoxiIhkKPhgSKjGICKSoeCDQT0GEZFMyXxs1MziwGSgD1ABjHD3ssj8y4ErgSpgnLs/G5l3PDDT3buFj78P/Fe47DR3n5rLtibDQfRSqRSxWCyXmxYR2SPlq8dwBlDs7scAo4G70zPMrAtwDXAscDJwu5m1Dud1A64DisLHRcA9wHeBE4ArwvVzJhkPwkC9BhGRQL6C4TjgBQB3XwD0j8wbAMxz9wp33wCUAb3NrBh4CLgqsmwvoMzd17n7VmAuMDCXDU0kgmBQnUFEJJCvYGgPbIg8rjazZJZ5m4BS4AFggruvaGQ76WVzRj0GEZFM+QqGjUBJdD/uXpVlXgmwlaAncIuZvQ50NLNZWZZdn8uGJuPBU6Cht0VEAk0qPpvZfkAHggLwDcAkd3+3kVXmAd8HnjCzo4H3I/MWAreFp45aE5wuWujuFtnfKnf/QVhjOMTMOgKbgeOBCU0+uiZI1p5K0k1uIiLQ9B7DDKAz8AvgZYKCcGNmA+VmNj9c9lozG2Vmp7n7KuB+4C3gVeAmdy9vaCPuXgmMAl4E3ia4KmlFQ8vuqIROJYmIZGjq5apJ4E2CN/FZZnZVYwu7ew0wss7kDyPzpwJZLzt19y6R3+cAc5rYzmZL1xhUfBYRCTS1x9AKmAi8aWaDyNP9D7uDagwiIpmaGgwXAw7cCewDXJCvBu1qqjGIiGRqajCsBJ4B9gIMqM5bi3Yx1RhERDI1NRhmAkcC44FKYEreWrSLqcYgIpKpqcHQgaAAvL+730FwmWmLoBqDiEim5hSfrwP+YmaHAe3y16RdK6Eag4hIhqYGw3XAvsA4YBCZ4xnt0TQkhohIpiYFg7vPB94ArgCWu/vCvLZqF0qoxiAikqFJwWBmtwOXEBSef2Rmd29nlT1GUUI1BhGRqKbeqHa8ux8LYGb3AQvy16Rda1uPQTUGERFoeo2hKPxWtvQ6LebjtWoMIiKZmtpjmAXMM7MFwLfDxy2CagwiIpkaDYawtpB+x1xBMJT2uwRXKLUIqjGIiGTaXo/hw8jvTh5HOd1dVGMQEcnUaDC4+/Rd1ZDdRTUGEZFM+fpqzz2GagwiIpkKPhhUYxARyVTwwbBt2G3VGEREQMGgYbdFROoo+GDQF/WIiGQq+GBI1xgqVWMQEQEUDKoxiIjUoWCIqcYgIhJV8MEQj8eIx1RjEBFJa+oges0SjsQ6GegDVAAj3L0sMv9y4EqgChjn7s+aWRdgJsHXiH4OXOzuW8xsFHAZsCZc/Up391y2N5mIq8YgIhLKV4/hDKDY3Y8BRgO1X+wTBsA1wLHAycDtZtY6XG66uw8E/kYQHABHAhe5+4nhT05DAYJLVlVjEBEJ5CsYjgNeAHD3BUD/yLwBwDx3r3D3DUAZ0Bu4Fngs7G10A1aHy/cDxpjZXDMbk4/GJuIx1RhEREL5Cob2wIbI42ozS2aZtwkodfcUkACWAIOAeeH8WcBIYDBwnJl9L9eNDXoMCgYREchfMGwESqL7cfeqLPNKgPUA7l7p7ocBVwAzzCwG3Ovua919K/Ac0DfXjVWNQURkm3wFwzxgGICZHQ28H5m3EBhoZsVmVgr0ApaY2WQzGxQuswmoIehdLDGzdmFIDAYW5bqxqjGIiGyTr2CYDZSb2XzgHuBaMxtlZqe5+yrgfuAt4FXgJncvD6fdYmavAb8ArgprEDcCr4XLf+Duz+e6saoxiIhsk5fLVd29hqAuEPVhZP5UYGqddT4ETmxgW48Cj+a+lduoxiAisk3B3+AGQY1B38cgIhJQMBD0GPSdzyIiAQUDQY1Bp5JERAIKBoIegy5XFREJKBgIagzqMYiIBBQMpC9XVY1BRAQUDIAuVxURiVIwEPQYVGMQEQkoGAi+91k9BhGRgIIBDYkhIhKlYECD6ImIRCkYCHsMqjGIiAAKBiCoMehUkohIQMGAhsQQEYlSMKBB9EREohQMqMYgIhKlYEA1BhGRKAUDqjGIiEQpGFCNQUQkSsGAagwiIlEKBsLvfK5JkUopHEREFAwEp5IAVGYQEVEwAMGpJEB1BhERFAzAth6D6gwiIpDMx0bNLA5MBvoAFcAIdy+LzL8cuBKoAsa5+7Nm1gWYCbQCPgcudvctZvZ94L/CZae5+9RctzeZCPJR9zKIiOSvx3AGUOzuxwCjgbvTM8IAuAY4FjgZuN3MWofLTXf3gcDfgCvNrAi4B/gucAJwRbh+TqV7DLqXQUQkf8FwHPACgLsvAPpH5g0A5rl7hbtvAMqA3sC1wGNhb6MbsBroBZS5+zp33wrMBQbmurGqMYiIbJOvYGgPbIg8rjazZJZ5m4BSd08BCWAJMAiYl23ZXDdWNQYRkW3yFQwbgZLofty9Ksu8EmA9gLtXuvthwBXAjMaWzaV0jUGnkkRE8hcM84BhAGZ2NPB+ZN5CYKCZFZtZKcHpoiVmNtnMBoXLbAJqgKXAIWbW0cxaAccDb+e6sbU9BgWDiEh+rkoCZgMnmdl8IAZcYmajCOoFz5jZ/cBbBMF0k7uXh9MeMrP/IgiFq9y9MlzvxXDZae6+IteNTdQWn1VjEBHJSzC4ew0wss7kDyPzpwJT66zzIXBiA9uaA8zJfSu3KUoEwVCpGoOIiG5wA0jEVWMQEUlTMKAag4hIlIIB1RhERKIUDEBSNQYRkVoKBiCpGoOISC0FA9EhMRQMIiIKBqKD6KnGICKiYEA1BhGRKAUDqjGIiEQpGFCNQUQkSsGAagwiIlEKBlRjEBGJKuxg+PubsGm1agwiIhGFHQxPXQFv3a0ag4hIRGEHQ0kXWPvRthpDtWoMIiKFHQwde8BXy2prDOoxiIgUejB06gEblpOsqQQUDCIiUOjB0LEHpGpIbPwUUPFZRAQKPRg69QAgue4TAKp0uaqISIEHQ8fuAMTXfUI8BlW6wU1EpMCDoU1H+EZH+HIZyXhcNQYREQo9GCA4nfRlGYl4TDUGEREUDOElq5+QjMdUYxARQcEQ9Bg2rqBdfKtqDCIiKBhqC9AHxr9QjUFEBEjmY6NmFgcmA32ACmCEu5dF5l8OXAlUAePc/VkzOxCYFrYpBlzh7m5mo4DLgDXh6le6u+esseElqwfHVvGPrdU526yIyJ4qL8EAnAEUu/sxZnY0cDdwOoCZdQGuAfoDxcBcM3sZ+DnwgLs/bWYnA7cDZwFHAhe5+6K8tLRjEAzH7LWesUtX84+t1XyjVSIvuxIR2RPk61TSccALAO6+gCAE0gYA89y9wt03AGVAb+A64LlwmSRQHv7eDxhjZnPNbEzOW1rcHtruyzF7rWdjeRVzFq/M+S5ERPYk+QqG9sCGyONqM0tmmbcJKHX3te5eaWYGTAB+Gs6fBYwEBgPHmdn3ct7aTj3Yp3I5h3Zux2MLPs355kVE9iT5CoaNQEl0P+5elWVeCbAewMwGAU8DF4b1hRhwbxgaWwl6FH1z3tqOPYh9+QkXHP0vLF6+gff+d33OdyEisqfIVzDMA4YBhDWG9yPzFgIDzazYzEqBXsCSMBTuA4a6+zvhsu3Dee3CkBgM5L7W0Kk7bF7FmYe1p02rhHoNIlLQ8hUMs4FyM5sP3ANca2ajzOw0d18F3A+8BbwK3OTu5cC9QCtgupm9bma/CmsQNwKvhct/4O7P57y1YQG6ZMv/ckbf/XnmvZVs2FKZ892IiOwJ8nJVkrvXENQFoj6MzJ8KTK2zTp8s23oUeDTXbcwQXrLKl8u44NtD+M2fPuPBN5Zx3XcPpSihWz1EpLDoXQ9qb3Ljq2Uc1rU9g3vuy0NvLONf73iVu19yPl69SeMoiUjByNd9DHuWVm2D00lvT4b2BzD1wn/jjY/XMHPBZzzwWhmTXi2jbasEh+9fSs8uJRzQ4Rsc0KENXUqL6dimFR3atqJ9cZJYLLa7j0REZKcpGNJ+8Bt45sfw9EgSi2cxePBYBl/YlxWbKnl72Ze8v3w97y3fwOy/rGBTRVW91eMxaNsqSdvWSdq2TlBclOAbRcG/yUSMZDxOUSJGIh4jGY+RiMdJxCEeixGLxYjHIBYLHwOxWIxYDGLEwunUBk+s9j+Ej8PpMagzq0l2R56ljyuVpSOWIlVv+fT0htbJdgyxZj8b9fddd3vpdje0XHR/6Tal29vYdhvbTnM1Zz87qqH2Zdvv9o5le8/39pbJt8b+pjuiKc/T9o43/To88sAODOq57443JgsFQ9q+PeHSF2HRNHj5Vnj4O9CqHft3G8A5XftyzoE94IjusNfhbIiXsnxTDas3lrPu60rWbdnKhn9Usrmiiq8rqvi6opryymrKq6r5R2U1VeU1bK1OUVVdQ3VNiqqaFNU1KWpSwU91DUCKmhTUpII3vlT6X4LfayJvLtEXZarOL9leUKlUw2+eTXmBp9h+2GRbpqHp6WNKz6vb00qlUkEwRpavOz26SvZwqb/NRo8hsky2Y6nb7lid+dFtRTW03caes53V1L9FY9Ozaax9Df2tIfvzX/dv3di6DW17R+Ozqes25W9KnWWacuYg2/8T0XWzbSW9LMBJh3VWMORdPA5HjYDDzoRPXoPP3oZP58PceyG1bRylUqC0VQmHt+kArUuDu6dbtYOibwQ/7Ysh2RoSRZBoBfEiSCSDf+MJiCchlgje3WLxyE/4OP2SiMW2/3tDmtIFSKXY9rKPRbob0XUb+d81Ff03+j9MbPv7b87HrtqP56nMafXa2lBTUw08jmyr9vluQluDBw3tpGn7ztheU2K2kW3UndfQ89Dc56ap6+2oxo6lwec41YQ2ZomzBnJSAAAGD0lEQVTlVAPPX1NfM9nakarJfN1kWyc6r6l/67rtjcW2s25knS7tt7P9HaNgaEjbTvCtc4IfgOpKWP8ZrPs7bFgOX6+FLV8GP+UboWITbPocqsqhsjz4t7oCqrYG/6Y0nLeI5EG3o+GyF3O+WQVDUySKgkta05e1NldNDdRUQU0l1FQHv6c/gaRqgt5I7e/pEIl+Yqrz6anRT9p11sv2qSP9iaT2E3kNDX7qyrou29aPbof0thrrCGdsrJFzXOGxpHtTxCLHV6etjX2Ky2h3ZH+1x51Nc5+PBvad0Ttq5FNw1m02cPIpY15DvYumnoxq4IRGo89lA7Z3jrI5Pa66z02Dn5rr9lTr/n0j+2rsNdOYuu2IJ+r3LOsed72/b3P/1s15XUbWad+1aftoJgXDrhCPQ7wVwf17IiL/3HQfg4iIZFAwiIhIBgWDiIhkUDCIiEgGBYOIiGRQMIiISIaWcLlqAmDVqlW7ux0iInuEyPtloqH5LSEY9gM4//zzd3c7RET2NPsBy+pObAnB8GdgIPA5UL2dZUVEJOgp7Efw/llPrO6IgSIiUthUfBYRkQwt4VRSs5lZHJgM9AEqgBHuXrZ7W5UfZlYETAMOAloD44C/Ab8mGFVsCfAf4fd0tyhmti+wCDgJqKIwjnkMcBrBwFyTgTdo4ccdvsanE7zGq4HLacF/bzP7NnCnu59oZt+kgeM0s1uAUwmeh/9094XN2Ueh9hjOAIrd/RhgNHD3bm5PPl0AfOnuA4FTgAeAicDN4bQYcPpubF9ehG8WvwL+EU4qhGM+EfhX4FjgBKAbBXDcwDAg6e7/CvwMuI0Wetxmdj3wMFAcTqp3nGZ2JMHf/9vAD4BfNnc/hRoMxwEvALj7AqD/7m1OXj0JjI08rgL6EXySBPgDMGRXN2oXmAA8BKwMHxfCMZ8MvA/MBuYAz1IYx/0RkAzPBLQHKmm5x70MOCvyuKHjPA54yd1T7v4ZwXOzT3N2UqjB0B7YEHlcbWYt8rSau292901mVgL8DrgZiLl7+qqDTQRfStdimNnFwBp3j36DSYs+5tDeBB9yhgMjgZlAvACOezPBaaQPganA/bTQv7e7/54g+NIaOs6672/NPv5CDYaNQEnkcdzdq3ZXY/LNzLoBrwGPuvtvgOi51hJg/W5pWP5cCpxkZq8DRwAzgOgX47bEYwb4EnjR3be6uwPlZL4htNTjvpbguA8lqBtOJ/PLT1rqcUPD/y/XfX9r9vEXajDMIzgviZkdTdD9bpHMrDPwEnCDu08LJ/81PB8NQd3hrd3Rtnxx9+Pd/QR3PxF4F7gI+ENLPubQXGComcXMrCvQFnilAI57Hds+IX8FFNHCX+MRDR3nPOBkM4ub2YEEH3zXNmejLfL0SRPMJvhEOZ+gYHPJbm5PPt0IdADGmlm61vB/gPvNrBWwlOAUU0t3HTC1JR+zuz9rZscDCwk+9P0H8Hda+HED9wDTzOwtgp7CjcA7tPzjhgZe1+5eHT4Xb7PtddAsusFNREQyFOqpJBERyULBICIiGRQMIiKSQcEgIiIZFAwiIpJBwSCyG5nZ62bWc3e3QyRKwSAiIhl0H4NIE4Ujtj4EHELwoepmgqGt3wIOJ7jr9jxgK8FQ5z0Ivilrorv/Nhwu+T6CmypXAOcTDHz2OdCZ4E7l89z9k114WCL1qMcg0nQjgLXufjzBMM6/BNoAM939OIJB3K4Mf9aGw0APAcaZ2d7AFOASd/828EegV7jd59x9MEFInLMrD0ikIYU6JIbIjvgWMDD85A/B/z+V7v5m+Hg+wXg1VQRv/IQj2/6NoPfQ2d2XhtMnA5gZBF8mBLAK6LILjkOkUeoxiDTdh8Dj4eB8pxB810VrM+sTzj8W+IBgzJqBAOFw598iGLNopZkdEk6/wczODNfT+Vz5p6JgEGm6XwE9zewNgt7BpwTDHt9gZnOB/cNlpgCdwmmvAz919y8ITjFNC9fvCzy/6w9BZPtUfBbZCWb2P0BPdy/fzU0RyRn1GEREJIN6DCIikkE9BhERyaBgEBGRDAoGERHJoGAQEZEMCgYREcmgYBARkQz/H2bUEq4yhB/yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.close('all')\n",
    "plt.plot(loss,label='training loss')\n",
    "plt.plot(val_loss, label='validation loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "plt.savefig('loss_sobelx.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the weights with last epoch\n",
    "plt.figure()\n",
    "plt.imshow(weights[-1],cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeMatrix(matrix,epoch=1):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    title = 'Epoch {}'.format(epoch)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    \n",
    "    height,width = matrix.shape\n",
    "    Mud = np.flipud(matrix) # I don't understand this code. Please tell me if you know\n",
    "    coordinates = [(i,j) for i in range(height) for j in range(width)]\n",
    "    for coordinate in coordinates:\n",
    "        i,j = coordinate\n",
    "        value = np.round(Mud[i,j], decimals=2)\n",
    "        relcoordinate = (j/float(width), i/float(height))\n",
    "        ax1.annotate(value,relcoordinate,ha='left',va='center',\n",
    "                    size=22,alpha=0.7,family='serif')\n",
    "    padding = 0.25\n",
    "    wmargin = (width-1)/float(width) + padding\n",
    "    hmargin = (height-1)/float(height) + padding\n",
    "    \n",
    "    hcenter = np.median(range(height))/float(height)\n",
    "    hcenter = hcenter + 0.015 # offset due to the character alignment\n",
    "    \n",
    "    bracket_d = 0.4\n",
    "    bracket_b = 0.05\n",
    "    bracket_paddingl = 0.05\n",
    "    bracket_paddingr = -0.05\n",
    "    \n",
    "    ax1.plot([-bracket_paddingl,-bracket_paddingl],[hcenter-bracket_d,hcenter+bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    ax1.plot([-bracket_paddingl,-bracket_paddingl+bracket_b],[hcenter-bracket_d,hcenter-bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    ax1.plot([-bracket_paddingl,-bracket_paddingl+bracket_b],[hcenter-bracket_d,hcenter+bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    \n",
    "    ax1.plot([wmargin-bracket_paddingr,wmargin-bracket_paddingr],[hcenter-bracket_d,hcenter+bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    ax1.plot([wmargin-bracket_paddingr-bracket_b,wmargin-bracket_paddingr],[hcenter-bracket_d,hcenter-bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    ax1.plot([wmargin-bracket_paddingr-bracket_b,wmargin-bracket_paddingr],[hcenter+bracket_d,hcenter+bracket_d],'k-',lw=2,alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlim([-padding, wmargin+0.06])\n",
    "    ax1.set_ylim([-padding,hmargin])\n",
    "    \n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    matshowplt = ax2.matshow(matrix,cmap='hot',vmin=-2,vmax=2)\n",
    "    cbar = plt.colorbar(matshowplt, ax=ax2, fraction=0.046,pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    cbar.ax.get_yaxis().labelpad=20\n",
    "    cbar.ax.set_ylabel('Weight value',rotation=270,fontsize=20)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefolder = 'images/'\n",
    "for i in range(len(weights)):\n",
    "    savepath = savefolder + 'weightfigure' + str(i) + '.jpg'\n",
    "    matrix = weights[i]\n",
    "    fig = visualizeMatrix(matrix,epoch=i+1)\n",
    "    fig.savefig(savepath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the static images into a dynamic image\n",
    "\n",
    "import imageio\n",
    "from natsort import natsorted\n",
    "\n",
    "image_dir = 'images/'\n",
    "imagepaths = [os.path.join(image_dir,filename) for filename in os.listdir(image_dir) if filename.endswith('.jpg')]\n",
    "imagepaths = natsorted(imagepaths)\n",
    "\n",
    "with imageio.get_writer('weight.gif',mode='I') as writer:\n",
    "    for path in imagepaths:\n",
    "        image = imageio.imread(path)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_img = model.predict(np.array([gray_img.reshape(256,256,1)])).squeeze()\n",
    "\n",
    "margin = np.ones(shape=(256,10,3))\n",
    "combined_image = np.hstack((np.dstack((normalizeImage(pred_img),)*3), margin, np.dstack((normalizeImage(filtered_img),)*3)))\n",
    "\n",
    "cv2.imwrite('predicted_sobelx.jpg',(255*combined_image).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
