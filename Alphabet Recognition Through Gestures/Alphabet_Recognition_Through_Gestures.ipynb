{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from mnist import MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist = MNIST(path='data',return_type='numpy')\n",
    "emnist.select_emnist('letters')  # 6 types: letters, balanced, byclass, bymerge, digits, mnist\n",
    "images, labels = emnist.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(-1,28,28)\n",
    "labels = labels.reshape(-1,1)\n",
    "labels = labels - 1 # make labels from 0-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(images,labels,test_size=0.25,random_state=111)\n",
    "\n",
    "# Rescale pixel value into [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "# one-hot encode\n",
    "y_train = to_categorical(y_train, num_classes=26) \n",
    "y_test = to_categorical(y_test, num_classes=26) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training - Test accuracy: 3.6506%\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "accuracy = 100 * model.evaluate(X_test,y_test,verbose=0)[1]\n",
    "\n",
    "print('Before Training - Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74880 samples, validate on 18720 samples\n",
      "Epoch 1/10\n",
      "74880/74880 [==============================] - 5s 70us/step - loss: 0.1750 - acc: 0.9363 - val_loss: 0.2872 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28722, saving model to emnist.model.best.hdf5\n",
      "Epoch 2/10\n",
      "74880/74880 [==============================] - 5s 71us/step - loss: 0.1662 - acc: 0.9381 - val_loss: 0.2950 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28722\n",
      "Epoch 3/10\n",
      "74880/74880 [==============================] - 5s 70us/step - loss: 0.1586 - acc: 0.9415 - val_loss: 0.2910 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28722\n",
      "Epoch 4/10\n",
      "74880/74880 [==============================] - 5s 72us/step - loss: 0.1535 - acc: 0.9416 - val_loss: 0.2938 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28722\n",
      "Epoch 5/10\n",
      "74880/74880 [==============================] - 5s 72us/step - loss: 0.1464 - acc: 0.9449 - val_loss: 0.2955 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28722\n",
      "Epoch 6/10\n",
      "74880/74880 [==============================] - 5s 72us/step - loss: 0.1439 - acc: 0.9457 - val_loss: 0.2947 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28722\n",
      "Epoch 7/10\n",
      "74880/74880 [==============================] - 5s 72us/step - loss: 0.1377 - acc: 0.9471 - val_loss: 0.3023 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28722\n",
      "Epoch 8/10\n",
      "74880/74880 [==============================] - 5s 73us/step - loss: 0.1327 - acc: 0.9498 - val_loss: 0.2967 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28722\n",
      "Epoch 9/10\n",
      "74880/74880 [==============================] - 6s 74us/step - loss: 0.1316 - acc: 0.9503 - val_loss: 0.3024 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28722\n",
      "Epoch 10/10\n",
      "74880/74880 [==============================] - 5s 72us/step - loss: 0.1272 - acc: 0.9511 - val_loss: 0.3138 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28722\n",
      "After Training - Test accuracy: 91.6122%\n"
     ]
    }
   ],
   "source": [
    "file_path = 'emnist_mlp_model.h5'\n",
    "if not os.path.exists(file_path):\n",
    "    # set checkpoint to save model after every epoch\n",
    "    checkpoint = ModelCheckpoint(filepath='emnist.model.best.hdf5',\n",
    "                                verbose=1,save_best_only=True)\n",
    "\n",
    "    # train the mpl model\n",
    "    model.fit(X_train,y_train,batch_size=128,epochs=10,\n",
    "             validation_split=0.2,callbacks=[checkpoint],\n",
    "             verbose=1,shuffle=True)\n",
    "   \n",
    "    # load saved weights to the mpl model\n",
    "    model.load_weights('emnist.model.best.hdf5')\n",
    "    # save the nodel\n",
    "    model.save('emnist_mlp_model.h5')\n",
    "\n",
    "    accuracy = 100 * model.evaluate(X_test,y_test,verbose=0)[1]\n",
    "\n",
    "    print('After Training - Test accuracy: %.4f%%' % accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74880 samples, validate on 18720 samples\n",
      "Epoch 1/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.9421 - acc: 0.7141 - val_loss: 0.3584 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35838, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 2/10\n",
      "74880/74880 [==============================] - 101s 1ms/step - loss: 0.5022 - acc: 0.8420 - val_loss: 0.2877 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35838 to 0.28767, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 3/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.4142 - acc: 0.8674 - val_loss: 0.2653 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28767 to 0.26527, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 4/10\n",
      "74880/74880 [==============================] - 101s 1ms/step - loss: 0.3653 - acc: 0.8827 - val_loss: 0.2393 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26527 to 0.23931, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 5/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.3350 - acc: 0.8896 - val_loss: 0.2271 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23931 to 0.22714, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 6/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.3090 - acc: 0.8975 - val_loss: 0.2192 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22714 to 0.21925, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 7/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.2891 - acc: 0.9035 - val_loss: 0.2156 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21925 to 0.21562, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 8/10\n",
      "74880/74880 [==============================] - 101s 1ms/step - loss: 0.2717 - acc: 0.9086 - val_loss: 0.2087 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21562 to 0.20868, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 9/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.2582 - acc: 0.9122 - val_loss: 0.2081 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20868 to 0.20809, saving model to emnist.cnn_model.best.hdf5\n",
      "Epoch 10/10\n",
      "74880/74880 [==============================] - 102s 1ms/step - loss: 0.2400 - acc: 0.9173 - val_loss: 0.2099 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20809\n",
      "Test accuracy: 92.9904%\n"
     ]
    }
   ],
   "source": [
    "file_path = 'emnist_cnn_model.h5'\n",
    "if not os.path.exists(file_path):\n",
    "    # set checkpoint to save model after every epoch\n",
    "    checkpoint = ModelCheckpoint(filepath='emnist.cnn_model.best.hdf5',\n",
    "                                verbose=1,save_best_only=True)\n",
    "\n",
    "    # train the mpl model\n",
    "    model.fit(X_train,y_train,batch_size=128,epochs=10,\n",
    "             validation_split=0.2,callbacks=[checkpoint],\n",
    "             verbose=1,shuffle=True)\n",
    "\n",
    "    # load saved weights to the mpl model\n",
    "    model.load_weights('emnist.cnn_model.best.hdf5')\n",
    "    # save the nodel\n",
    "    model.save('emnist_cnn_model.h5')\n",
    "\n",
    "    accuracy = 100 * model.evaluate(X_test,y_test,verbose=0)[1]\n",
    "\n",
    "    print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = load_model('emnist_cnn_model.h5')\n",
    "mlp_model = load_model('emnist_mlp_model.h5')\n",
    "\n",
    "letter_mapping = { 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j',\n",
    "11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't',\n",
    "21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '-'}\n",
    "\n",
    "# define the upper and lower boundaries for a color to be considered 'Blue'\n",
    "blueLower = np.array([100,60,60])\n",
    "blueUpper = np.array([140,255,255])\n",
    "\n",
    "# define a 5x5 kernel for erosion and dialation\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "# define blackborad\n",
    "blackboard = np.zeros((480,640,3),dtype=np.uint8)\n",
    "alphabet = np.zeros((200,200,3),dtype=np.uint8)\n",
    "\n",
    "# setup deques to store alphabet drawn on screen\n",
    "points = deque(maxlen=512)\n",
    "\n",
    "# define prediction variables\n",
    "pred1 = 26\n",
    "pred2 = 26\n",
    "\n",
    "index = 0\n",
    "\n",
    "# Webcamera no 0 is used to capture the frames \n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current paint window\n",
    "    (grabbed,frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1) # flip horizontally\n",
    "    \n",
    "    # defining range of bluecolor in HSV, creates a mask of blue coloured objects found in the frame.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # change color from BGR to HSV\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # determine which pixels fall within the blue boundaries and then blur the image\n",
    "    blueMask = cv2.inRange(hsv,blueLower,blueUpper) # filter background(lower blueLower and higer blueUpper)\n",
    "    blueMask = cv2.erode(blueMask,kernel,iterations=2) # erode images\n",
    "    blueMask = cv2.morphologyEx(blueMask,cv2.MORPH_OPEN,kernel) # remove noise\n",
    "    blueMask = cv2.dilate(blueMask,kernel,iterations=1) # dilate images\n",
    "    \n",
    "    # find contours (blue circle) in the image\n",
    "    (_,cnts,_) = cv2.findContours(blueMask.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "    \n",
    "    # check to see if any contours were found\n",
    "    if len(cnts)>0:\n",
    "        # sort the contours and find the largest one\n",
    "        cnt = sorted(cnts,key=cv2.contourArea,reverse=True)[0]\n",
    "        # get the radius of the enclosing circle around the found contour\n",
    "        ((x,y),radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # draw the circle around the contour\n",
    "        cv2.circle(frame,(int(x),int(y)),int(radius),(0,255,255),2)\n",
    "        # get moments to calculate the center of the contour\n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))\n",
    "        points.appendleft(center)\n",
    "        \n",
    "    elif len(cnts)==0:\n",
    "        if len(points) != 0:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard,cv2.COLOR_BGR2GRAY) # change BGR to GRAY\n",
    "            blur1 = cv2.medianBlur(blackboard_gray,15) # blur image by median filter\n",
    "            blur1 = cv2.GaussianBlur(blur1,(5,5),0) # blur image by Gaussian filter\n",
    "            thresh1 = cv2.threshold(blur1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1] # process image by threshold\n",
    "            blackboard_cnts = cv2.findContours(thresh1.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)[1]\n",
    "            if len(blackboard_cnts)>=1:\n",
    "                cnt = sorted(blackboard_cnts,key=cv2.contourArea,reverse=True)[0]\n",
    "                \n",
    "                if cv2.contourArea(cnt)>1000:\n",
    "                    x,y,w,h = cv2.boundingRect(cnt) # find bound ((x,y) is coordinate of upperleft point, w is width, h is height)\n",
    "                    alphabet = blackboard_gray[y-10:y+h+10,x-10:x+w+10] # width and height respectively plus 20 pixels\n",
    "                    newImage = cv2.resize(alphabet,(28,28))\n",
    "                    newImage = np.array(newImage)\n",
    "                    newImage = newImage.astype('float32')/255\n",
    "                    \n",
    "                    pred1 = mlp_model.predict(newImage.reshape(1,28,28))[0]\n",
    "                    pred1 = np.argmax(pred1)\n",
    "                    \n",
    "                    pred2 = cnn_model.predict(newImage.reshape(1,28,28,1))[0]\n",
    "                    pred2 = np.argmax(pred2)\n",
    "            # empty the points deque and blackboard\n",
    "            points = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480,640,3),dtype=np.uint8)\n",
    "    # connect the points with a line\n",
    "    for i in range(1,len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame,points[i-1],points[i],(0,0,0),2)\n",
    "        cv2.line(blackboard,points[i-1],points[i],(255,255,255),8)\n",
    "    # put the results on the screen\n",
    "    cv2.putText(frame,'Multilayer perceptron: '+str(letter_mapping[int(pred1)+1]),\n",
    "               (10,410),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),2)\n",
    "    cv2.putText(frame,'Convolution Neural Network: '+str(letter_mapping[int(pred2)+1]),\n",
    "               (10,440),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),2)\n",
    "    \n",
    "    # show the frame\n",
    "    cv2.imshow('Alphabets Recognition in Real Time',frame)\n",
    "    \n",
    "    # stop the loop util pressing the'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Destroys all of the windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# release the captured frame \n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
